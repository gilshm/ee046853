{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ee046853_01_pytorch_intro.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErJIitJV4qJv",
        "colab_type": "text"
      },
      "source": [
        "# Technion - EE046853 - Advanced Topics in Computer Architecture\n",
        "Welcome! In this exercise, we intend to give you some hands-on experience with deep neural networks (DNNs) using the PyTorch framework.\n",
        "Even though this exercise is more oriented towards the software/algorithm side, the stages of develping a DNN and the techniques you'll employ here have major implications on current (and future) hardware architectures.\n",
        "**bold text**\n",
        "This exerecise is organized as follows:\n",
        "1.   **Part I: Introduction to PyTorch** - Train a convolutional neural network (CNN) for image classification for CIFAR-100 dataset.\n",
        "2.   **Part II: Quantization** - Explore quantization impact on model accuracy and hardware.\n",
        "3.   **Part III: Pruning** - Explore pruning impact on model accuracy and hardware.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkiVivsTDjRx",
        "colab_type": "text"
      },
      "source": [
        "## Part I: Introduction to PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA-qWZVVDp9A",
        "colab_type": "text"
      },
      "source": [
        "### CIFAR-10\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "We'll walkthrough how to code a CNN for image classification with PyTorch for the CIFAR-10 dataset. At the end, you'll do the same thing with CIFAR-100. More details can be found [here](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/gilshm/ee046853/master/imgs/01_cifar10_dataset.png\" alt=\"CIFAR-10 dataset\" width=\"600\"/></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjUej52qDviq",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch\n",
        "*For readability, this walkthrough will not detail each an every function argument; you are highly encouraged to check the PyTorch documentation by yourselves, and if something is still not clear, e-mail me.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkAVvNwtD45X",
        "colab_type": "text"
      },
      "source": [
        "#### Loading CIFAR-10\n",
        "PyTorch is capable of downloading CIFAR-10 (and 100) automatically. Notice that batch size is set to 128, i.e., each feed-forward consists of 128 images.\n",
        "Regarding the *transforms.Normalize((...), (...))*, this is input data preprocessing (normalization) - for further details, see [here](http://cs231n.github.io/neural-networks-2/#datapre)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm3UWmjY1qpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "901bde16-b4b9-47ff-d576-b497e990d2bc"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                                     (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 169041920/170498071 [00:11<00:00, 16118192.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2DL5R8G2JiI",
        "colab_type": "text"
      },
      "source": [
        "Let's visualize some input images from the training set. Notice how the train loader will load different batches each time, since we initialized it with *shuffle=True*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj62zL9jCQlE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "346aa168-6e5f-41bd-d252-c0476bc4c3a8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "  img = img / 2 + 0.5     # Unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.show()\n",
        "\n",
        "# Get a batch from the train loader\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images[0:4, :, :, :]))\n",
        "# Print their labels\n",
        "print(' '.join('%s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO29eZCd13Uf+LtvX3rfu9ENdGMhQIIE\nSRDcRFKkKJGmFkuKo7LlaDzKRFVMqpIZ2ZWqRB7XlMyZ/JHUTCWZVDJOqSxHmilJtCwpMi1bEimI\nFFeQBMAF+97ofV9ed7/9vTt/nHO/c7rRTQAkBeDJ91eF6of7bffe737fd875ncVYa+Hh4eHhUXsI\nXe8OeHh4eHi8P/gXuIeHh0eNwr/APTw8PGoU/gXu4eHhUaPwL3APDw+PGoV/gXt4eHjUKD7QC9wY\n84Qx5pQx5qwx5msfVqc8PDw8PC4P8379wI0xYQCnATwGYATAmwB+31p7/MPrnoeHh4fHRoh8gGPv\nAXDWWnseAIwxTwP4HIANX+CpVMo2NTV9gEt6eHh4/P3D+Pj4jLW2fW37B3mBbwIwrP4/AuDe9zqg\nqakJTz755Ae4pIeHh8ffPzz11FMX12v/tZOYxpgnjTEHjTEHs9nsr/tyHh4eHn9v8EFe4KMA+tT/\ne7ltFay137DW7rPW7kulUh/gch4eHh4eGh/kBf4mgB3GmAFjTAzAFwE88+F0y8PDw8PjcnjfNnBr\nbdkY8y8A/BxAGMBfWGuPXe15vv71r7/fLgQw6zjSWFj+qxAyq4+rVoPflVL50l1CdLQJyXeuysdU\nKxUAQDgc02d0Z5PzVkoAgPm5KWmr0nkLhSIA4PTbh4Nty7PTdN5kfdD28Kc+DQBobG4L2p566t+s\nGsvhC+PB72g0irUI8cBCYWkLh+k/sViM95FxOu+kqpojY+gcxWJRnZeOiTlZQHk15QoFAECpXJJr\nRqhvyWRd0JZIhvnQMp9D+h81tC2l+p0v0fWzxXzQVuL7kYhSH5Mpmb9qOEn9r6ixFHMAgKa0vn+E\nL3zytwAAdfVyjng8DgC4ODgYtF0cGqJxcj8Ov/12sO3C8EXuV0GNhR63u++8M2i7/bY76FopIvfH\nxkZk/xjN6dat/UHbHbtvAwCEjFqTvMorPAdVJZYVea7CYWmMxxP8Sz0dprqqyarnoMzPxuiIrLEz\nZ84AAF577TXpb8Nqju0nB/9OjYXmOZ+TexaLUj8K+VzQtji/QNcsUkfSjQPBtlR0E41pcTFoWyqu\n0Lkqch/d8qmA11NE7nu56uZDBlhXn6ZzxKQtm52n82eWAAAGco5wlO5pLHnps1G18kqNJeh3NEqL\nt6mpQfrIr4iwugWt9Y0AgFt778aV4oOQmLDW/h2Av7vsjh4eHh4eHzo+0Av8RoHlr58WKFybVdIw\nqiw1s6RnSyIdhVlSXlyYlTaWmBLJZNA2MU5SiJNMOzdtltO7bhj5MueyJCFk52aCtkrRSeUkSeQX\npoNtS9N0/v7trdI2S9JAXXMnNsLS0pL0myVrJxUAQDxOEoqej0iExpfLiQTk4I7V0ny5TPNWKolE\n7aT3Eg/ZaSaAaC4VJflWWSINVWW/Yr7M12IJX24LKmUaSzQi/aivJy6lLi2cSrlMklUkRNdaWlyQ\nc4TohKm43MfUOlpK0B/WHGLNzUFbmOdjx66dsh+rfq8ffAMAML0kkuGWbf3Ux6RIhhfOngcAnLtw\nJmjbffPNAIBXX/wV9SsVD7Y9+ND9NN6Eki5ZgowkEpBG/huhuaoo6TkepznSa2G9X5Z/G5bsV+3P\n4vjKynLQVmItrLVV1mlGlgUAIF+QdZXN0XOgtbz2pg46r3puZ4tzAIB0YisAoLFBpNGJYZaKJ4Vq\nq/Jaj6ixIEJzaPlaoYjMX4i3RePy6pvj56tSkWcoFid6r+Q087A4YISq/I6oqGfa8KKNybqq8I2p\n8rtlaVnO399M89asNO3dN9FayMgyuix8KL2Hh4dHjcK/wD08PDxqFL8RJhSnoGvyJuTINCuqetiS\n2rc0RgTT6NB5OYC3xZVqFQWpqcWEqN4mTyRMglXw+aHTwbalFVKz5hfmgrapGTKPpPV5uaPxGJ3/\n7tt2Bdvid94CAFiYEBPAzMWzAICe/m3YCFrldQSkbnNmjIRS6Z0JZT3C0qm6zhyjf+s2R2iWyjTP\ndWkhJyO8X0Kdt8Tmo6pVZhU2zURjpN6mlGnEWmrL5cWu4shRR64BQAR03gYmiqrK7DC7TPtnCkK+\nFnit1HWKmcRhaTEDAOhs75BGHnK4LP2+ZYDuR4SXmlOBASDMBHhUmYqGe/sBACdPngzaVhZIX+7q\n6aIGtf+Zs2RqqauT+XCmmbKVsVue35BjHtX9MfZSIn699aG24hLw+TMZMQG8duAAAGBmRswIm3fu\nWXOgnL9YYFOE6kdmaYX7L89X3+a7+ch+AMBKWSK3l/OnAABLi+IrEY6leX9l8nGOBSE2GxpFisdp\nfdiSmCMLJTL1FJgQBYBUks5bV0fEbGeXrJNMhu5LKa/iWqI0R2FlmYuyx4AzW+ZX5PxNm8n0+sQD\njwRtm7uo7acvHMGVwkvgHh4eHjWK3wgJPIByYTOWJb2SfPVGzp0AACwO0pd8bGwo2BZL0LcsmxWi\nZnk+z+dSkgq74yWTJBVVCiIxrazQ/tPzQoSC3beUFxdyy9Sn8WEiY7b09QTbWupI4sxnxN0qw0TH\n1ltvW2fQhLo6kXwDdzIl+WZzJC2UytKRtVK2k8gBkdIccQkA6TRJJUlF6rpjV1i6WFzKyP6sudSn\n0rI/uwUWrfSjzBpJiVngipIrIizFJBVpFw3RvY2H5H63s+Td0EDXyg2L22YqkMZlfKGqjGstdmzf\nTtdRRKdz24tWZS3E2GVsRw8T2VE5//AQaXnjo8ot0NC9/dQnPxu07buXsk+UWVo8cvSdYNuLL/4S\nAHDXQH/QZtI0p1ZJnBGeryprQdBEsttNSfYm+KukVh6fk+b12imy5jI6ImNxboQjqm2tBN7YIBpM\ntUzPRCwumpFzi42zeyAALGZI0p1bYM1LqdXlMmkA5fyktOX5HhkZX4gHbUJ8P4xoJKUwP18hkewj\nUXqWw8rHNpclDThSIA160XYF29j7EcWKrA/nHpuKCAldYbK/ws4SqTrZNjNPWnomI++naO/VBzp6\nCdzDw8OjRuFf4B4eHh41it8MEwoTYmHl41zOEzl07sibQdvISYqUmz1LGW/jiuiqsu/2yKj4mOYy\nTJaV5bxJNgtk2b87tyAqUImdoTOKrEiwaaOkVDw36fMj7P+9IETQMJNxoZDcmrbde3i3MWwETUg5\n1V+bP+JMEIbVHXemFufXXVGqt1OhS+oczl+8XkUoOlNLup7GqaNiK6x6F/NiDgo5E4ryJTdsCqk6\nci2sIudctGVZzWmaxrd5kxBRPR0tAICmpnoei8zH2VFSV4tl6VyxtLEJxZl+dMSpMzEUlenFsDmt\nyDT6goohmOPowuWYqM1oI9/f4zPi959lQnNyinyRZ2dlG9hXeDgjZr0f7yezyqZ2iXrsaSFTRXMd\nmZEak8r0o8jiS6DMWGJroTnKqTV88hQR9S+9/HLQ5p4TvWbWor21O/gdj9CcRqNiCguF6V4trYiJ\nbXyC+pQvMjGbELOGLTKJrodgHFGoSHFnLqqu07cSmRIrmA+aTJzMNsbIvSqVOEYD1O+xpQvBts3b\ndgAAkgmZvyj7f3fWS7RlfR2NbzlHZsViWZ6DZX42jp8RJ4hSQY/syuAlcA8PD48aRc1K4HYVYcmk\nXUEItMMvPgcAmBsWl62ZISIvZ89RW1QRY1X+rs/OivteIU9SYmOjEB7FLLVNDhN5E9EuSkzuuRwI\nAGA52UFCSftgl6odW4j8iitXxwtDlGI91CpSbk8DfdVPn5YIvrWYVu5cQY4TRcIlEiRdVKqlS/Zz\nf3WE5XquhfmCCpFkOEIzw1Fm1ZKMJc6kUCgk/Ujy1NRXRbpNp2h7nqP1qkryjUep3y1tQtLexm6X\nHSx1A0CpQJLVMSYBW7u2BNvODtPcGCWvuAjS9VDmyDkTvtS5rqSIynnu7+j0BABgfFqI03dOsctb\nUST2Ct/n8cmJoC3/C1qnpUV2ZSvoqFiaezcvABDi+9fRLGNvTtNauZ3zpHz1n/5PwTbHS1eVe2BA\nXip1SZ4njl5UroguT1BmQUIEyyxBptIiPa9FUbltbttCOU3S9UIGHj1GY51QiqWL3rTu1VSR+TZ8\nX7TUWWGNNaGI8p27KIozxeR/OCKku2VSNLMkz0uBNbN8QWllJTq2jbWmhQV5NqKsjQ1sEbfeu+8m\nqTytHB62DhAZvlSlMb3y0i+DbcNzNOjFvMzpa2+QhjOw7cpzoXgJ3MPDw6NG4V/gHh4eHjWK3wgT\nSrVE5MDFk+8GbdNDZG4oZ8RnNFxkEwubWkplFZlXJNWnvKLNBGw+qIj6lGUib6Cfkt3UtUgynyyT\nnZm8nDfD6TM3b+4N2hrZ5/fNnzwPAFiZEtW7dTOpmMNVUfF/9Byl7Py9TbuxEXR0pCM09RzNcZrO\nqlWqIJtYoqxnryIW+RyapCqwCWVZJeVJc+RlLMXmqIpW1dm0VZY5DfG1djbJ0muu47SbzXSucknk\nirEpIgYfe+CBoG2FfdrnJkX3npsnlTgWdj7Rcg9KTIQuC4e0KhHWWjhCrKLoMjeVR06JGetvf0kq\n8dkR8vmeWRETXoHJww4Vzbm5i0jXnX2SAM0ywTt69hwA4NBxWcNdvP9HbhP//85WIi872iS1cIGz\nfyVSZCqoavKOVXqdJVnWhyL+ApKdo2eVr/8tu2nd7b3t9qDNRRmOT8nztRYRRdzPzlCStlRaTCiL\nixzFWxTy0LKJqOL6ptZkmf2pNTXZ2Ezmzc//zheCto8/9lEAwNGjZCqNRcW8Ul/XxOdX5kJOdlVR\n5o9yjtZ4iiOXZ+ck6rLCsRQDW2UsN+3iWI6smMAciX/kGBGVm9uFdC8xmapCGbB33z4AwJTwq5eF\nl8A9PDw8ahSXlcCNMX8B4DMApqy1t3JbC4C/BNAPYBDA71prr+K7oc7PX9qqWeUcRNsgUlSVU7tW\n+SsZVi45sxcownKWc4YAQJyPnZsWt8C5YSIILecFMYo8jLBUrHOhOEpDCZVoaCHJp7mDJKGoIk9W\nOIdGVCVEaOd0m+k6ISWPv0KujdOcmrajWRU3YIliZFTIjdFp+l1YVBGeUOlEAaSUxLQeAemkbaPm\nuWpX572IKCm+XCnz/pe6J+rDsixxFNi9Lh5VqU+ZHNLEZqKe+tmXEtmhOU7SUB9HpBaysn8vuwyG\nczIfL/385wCA1m6JYE0zqZdjjefl138u2zqJ1Aqpah3axXItXDGQitrnzbfIBfXFA68HbZkcufdt\n7aV+9IWlPzOTpFXt3XlL0Pb4Iw8DAFpScq+cxjA5R/f2v//4x8G2m266CQDw0EMPBW2NKVorOkp0\njlPnLrNrq95mlaQp4HWhxXJ3U82lm1zq2Jt33hS0RbhIQenwwXXOTxgfPien52tOz8i9XVogibRa\naZT9Kqv7aysqEpifoc2ttwZtD36M5nTf3ruCtu1biTz83/+Uip5MjotrZppdLWMqv1FjB7k7dvdK\nhcj8Ms1pPMo5baKisbU2U+TozKxozq/zPDQ3yvsgzuvt6b/8FgDgD//g94Jte7dTWuKckvo39xDx\nPjUvEeKXw5VI4N8C8MSatq8B2G+t3QFgP//fw8PDw+Ma4rISuLX2RWNM/5rmzwF4hH9/G8ALAP71\n++oB2+usykPgPkohq12w6Evo8hwsjJ4Ito0dI/ebzLh8EacnBwEAK/PislXO0dc9xiW2quZSR/yo\nCgiIJ+irm1aloqJcqivaRNtc6ScAiIRJKjbaVY/dDCeGxW3p+NtkExvoIGm7pPpxgQ1gt9y8PWj7\n9GMkGSycPRS0YUBswgCwkhUbnbOHJ+JiW2zk3yH1zc5yNjUX3NPSKFLGLLuM5Ura1YzzZSgjZJhd\n0apL1O9SQrQJGJrn9pAc0J/IcT+Ui1kvSyMTZE+NLovNfEcTaTyHXnwpaJs7RtnaokWZ54lxmt/D\nx0nqu2nPHcG2IqtQkaiMfTHrJHqR/hzcGsvltd2TxvA7vy2yTO8WksQsF1JYzIq7X56DbxpCcg/6\n2kkbi64TDNS8nVzS/vH/8KVgW47t4031MqdR93Coc2QWuSCBC2jTdQHXiWWxazQvQJUStMFOwTYX\nBDagSrtluHjFvr1SHi6z5rRVFcBV5XUylxVNqlKie2u1NuSCuXiRWbVO+jbT9R978MGgbS5Dmst3\nv/vdoG3rwL8CAEyzFqSLtGS4WoKtSmcbOctiUVUSGRuiwJ3FOXp/RFTpxOYWktizii+LsqbY2SWc\n2Gc/+xkAQEsraRqVnIzznrtJY5hRwWUHD3KWRaOeocvg/drAO621rkDeBICNS8V4eHh4ePxa8IFJ\nTEuf83WSCBOMMU8aYw4aYw5mlZTo4eHh4fHB8H7dCCeNMd3W2nFjTDeAqY12tNZ+A8A3AKCnp2ed\nF725pCXkSExVaTrGKUTnLpL6/ObzfxVsW5okN66lWflAlCukqmsSM14lE0GinnIfWJUYJOTIt6io\nvCGO1qtXqVrLbO5wxE4uK2rUwgKRmKG4mCKqBVJr3zkqhE64ngi3eVbLx6cl+rNnG5kd8ionRrKP\nVLYTp4Wk3bTGhKLdCEPrVI8PG5c6Vo2Z25IcXdjdIa5pLuoyEpNvfDHMKqBKqVpxBKWh+S6rb3mc\nTWCNqtp3ivOcJJrkWlPzpMLm2GWwv0miDE++S/f71LC4DN55M5FY9b0SbfnswaMAgKZWcu26dY+Q\nWkc5KnJEubzF6zaOIHTkbkwRsj09RFB2dojJpYEJ7yrPd1mZ31zkbUeTFAIoVnh9qghIl2OlyhUm\nGpJCTluuKK9d6SIxV6RA+hvlCuspXnd2lRuhIycvfc5WFaVfs7/OLVLH0ZbdneI2l99BY9l7t8zz\n9/5WIg0BoEGZ0yrsL7dSlFwhhby7qq5bS2smyIujtiW5HzfdIm6Vv3zhWQCrc7e4lMWrTEmMGNdd\nVfw+cmz+u3BS3GMt126NOpdLRabOT5EzhDHyLBXz1N+Lym3ZVn4LALCpl9xGpxWZuqWbnunBU/Je\nWGETTiz+6zehPAPgy/z7ywD++n2ex8PDw8PjfeJK3Ai/ByIs24wxIwC+DuDfAvi+MeYrAC4C+N33\n3QOz5i8A48hLlQVw6txbAIDXf/rnAIDRi0LopeJEIJSyygWQ3ZGKiliKcSY0V8m6rUMkiiJLklUj\nUnyxSFJlVQcTcN9y7D5XLsmnvMR5HGIq90KVSc4hVWCggSW78Wki3h64RwjLex/YCwA4cUayn+Xn\n6KveXLdxJXXtFudIqlVkFRN55bDOhcIunHzs0qIQTEEgTFUk+yhLNAVF9rhLhOMkHdWr4I2eOprv\n9ricI91KEuzkkszzzAxpLvEsF9Aw0o8zMzRv6S5J+r/C+SxOvnU0aFty52ukuU8qSfbueyi3xNSz\nz0m/3ytJH4tnYVXgosjScG5F+l3PQR6uXJktyNzmlojEDLWKpuFI4PKq4gP0110pqkqO1bFrqM4o\n6Eqk6bw1TpyMsWufDuQJrVM+bV04Ui+QfPXaofXRkNbBPVQ+rlTZ2B2zpPqdZHfbSkQ0n/mFCl9L\nZX1kBwAn3RpF8Fd5W0aZYmPsaNDSJo4G6wWyOTitVBezAJPs+lqW93Nzn1Tuwo54jisNYzMXAVlY\nlsyRIS4eUeF3xMS0SOALs7Tmn/nhM0Hb0AS9Dx5+9DOX9HsjXIkXyu9vsOnjV3wVDw8PD48PHT4S\n08PDw6NGcQPkQllHteNUoyfffjFomjlKfsBTx1+hXfKSd6LcQGp5XULyTswtkJoVC4kqbcA5D/ia\nIZUaNMLER1Kp1hFWI7PKtJDnKM5oms6ViIh5YGrZ5U8QEm6IE9+XC+ITm2fzzhOPUqGGVFxUyNlR\nIio3NQsRevL0eTpHTs6xNpOHzlniVEdd49LxjqWSXCvEqnacibEmVf18gqNEIxEVWelUTOVPneO8\nL9kSXaAhLhO4o5NUzOaUqJrzKzT2E2ck2qyRycC9OyjlaKxeVPU0+4QX1ZyOj9Cxw8rvvxSha3Rz\n+s+du3bI2DmdberlV4K2lcJ6EYqEimO4VNSqS86vU8y67U4dt8pnPsHqc1i1OWLOKnIt0NrZrBJS\npgtnsiqrNL6W12whLzk3klxnMuiZ8nF2aWRDOv2yM6doE8MaE8pqxzI+h+p3jAuO2NClZgqHsrL4\n5ZgUXcmLiaFc5mdJFfAIsf93mQspGNXHUpnu2VJezKKuFqtRa93Zpex6ViPjSEy5j72c9nXLTTuD\nthNvHAAA5NnPXJuDQlz4oU3ludm5734AwLZdki+mi1M4H32TzL0nh2TNP/cc5UGaH1NpbddJ13w5\neAncw8PDo0Zx/SXwoGq2fOGmR0jiPPHmT4K26AK5CoIjucrLQp44nq2qpIGwJakkGhapsrODMgKW\nWSCsKLLHRdoVc0KQrCxQKa7lrFwr1UhuYTFXLT0mYkba5YdYESljiF3/mqPSt11b6RwP3EUS5/Sk\nfJmLLFktLsg5du4gCSGiylENYzVWuQyuU6AhEadjwxFFLHEZuZv6aV66eySXR7nkSruJFDo9Q+6O\nhbKcI+XyesTJPey+AXGbi0xQ6bqSkf2PnaHINhsRqXzP/fcAAD5yN0kvk4Ongm2heZKw8gVZqnMc\nUVtWy7euga67g/OHbN06EGwbnSQpKqxy1DjCbz1U2XXNKhEumSRpqlxUrqosEbpq5tr1zuUj0ZqR\nCXGZMCv9Dls6rzVlPodaw6zduesAQI6z2GWLIoGnmWArcEECo0ulseS4KhvhpUNW4DFo6Vx8DKWJ\nVbroOq56wT6rCmLQWJaXRHous4geWpWfp8qX536E5dkrFOjZL5bE3S/PWQPjyUsJ5/Xy3axHbC5z\ndObinERsptnNtIlzm8wszKttpI2FojL2lQxJ0s0p0Vjr+Zlz2RAnZ6TfS0X6/fkv/HbQljN07PT8\nlUviXgL38PDwqFH4F7iHh4dHjeL6m1AY2k11foJMCtVliaLMzNNvV78upCpIL82TuaFixVwSZl9r\nXdvPJeBpYaKroqtEcyrY/Iq0pTmJTzGn/HBZJc4vkQqUVFGaaValL1yQiMnyMl2zo0HMH/fcSj6r\nmblBAEBuSSIxXdXunk3i9xypJ7JE13kclhxd1EdVf9Cp3jo6c56JWFMR9SySpLlcmiMyMKxU5AzX\n2OztlX4sRWh7MiFz7wjCaIpMGM7sBACbErRtck78X5tbab97H34kaLtlJ5mIjp4gv+5j77wTbIty\nVNrErBDJBSaSW7uk6nkkRYnB7r2XzDG6BunMLI1lbk7U4ET60iRWwZic+q6SqcV4Tk1FZJ4Cm9ui\nTAKHlQ83eC1kK3JfXFCrqcpjV2Fzh7M2FJW5JOTOp86b4WvqGpfxOEfvMqFnV5lQ1vylAeISBIe4\nyE1Z827vqnpIwxxXENrYEoWCKmwSKrMDQUXWjgkIxUtNHe4e6KRniwtErA8NSiX3CX5XbFaphV0a\nZVevdT2CP1+QtnyW3h+TwxJ7wUsdySZaJwM3SSpdZ5rUNUKff/anAIADL0g06pe+QOExrVzPNaXS\nRj/8afLCXinIvfibZ4lkb2yS4i+Xg5fAPTw8PGoU110Ct+4rXJEvfsTSV3fsrJBZRf5KVrnUWG+n\nctUbGgQA5Obka9baTQkSixUhDsIs+VQrREJElPjgUtcmIqpyuZOiluQcESbwquz6FFfFCmY4X8fU\n0HjQ1t1M5F5Pp0ge/X3U5sjAiEoWX1dH2kH7QL+0dVKq0foOKcX1wt8cxkYQyUbm1EWmhpVUGXE5\nUzh5fValzEywSNjRKIUo2ttozguqwoXLDTMzQ9JfWdUtG+FUnA2Ncq92dJBE39osEvBrr1HJuDde\npbTABRU9W8d5a1y0JgA0MWnX0iLnvesBSux/083kPjgyIjTvK6/QeSenRBOIxEiS3d0nkZLBtqor\niKFSBfNUhlR+lDJLjs7NT7sHOpe7yiqXPlp/5y+IpDc+RsTZnXdR2TJd6s1Ji1GlTRQWuHxaQvYz\nztUzzNHB6ppBj1T+mnBQu0Htd4lQbtb9+Z5ta5DP6ZKFdE9DaAra3ByZVRdf3RZSjglZ1u5yqnRd\nniNjdYRsMG9MJMdiMn+O8F1SOYzKHOFZLsi6S6apn66c3O47JD3xIhOxS0pbP/QGFWk5evhA0DY4\nRJrC1q2UDjrdIu6xSNE7YGJUcqEM8Zq9zUvgHh4eHr/58C9wDw8PjxrFdTehBFAqWYGTQuWUP2TX\npn4AQIarfAxOXAy2tbWTWjQ8IapVrkAmi1hKZy2iY0Nc7TKsLuoSYhUVyTfLyWeyKkFNboHMKWmu\nyJNRZMjyHKl4bQ2iKiXrSX1rb5O2SpWuUd/cxucS3+meHvJfbuyRyh7xDjKhJDqExARWm1BCiuha\nL3GRS7gUUtua6mkM++6g9Jw9myUS7RSnYI0o3+adO8k8Ma8qbxsmemdGiIAZuSj3ZVMDbetS/uVb\n2cTxxtG3grY33qB6gjNTRDZmMqLKNtTRtdrUHLVy3dB99+wL2h771OMAgGqcxvnmm1K7cv/+XwAA\nEikxl1TNxks/5IaszHoVJs+NMrGVXWIpjup0aVcB8csPKzNWllML/+JFiQg9c4YI75Khc+xVFW5c\nwrSESsw1z0m74nk5r0tlmlum/ZUlDKkk1zFV5hIXUauDKCVSk6OUlTkoSI6mxuIq2tj3SJKVXZF1\nEo07U5z44rtraPLXmX9cdGtYnX9lmdZFY72Y3z7zSUr8lFRmksUFMglOTRE5r2ubBjUJjPTDGJfI\nTp7lex6hNLn33EOkeFevmC8vTNL5P7JH1t+jn6bkrAee+4WMJUsmkWU2+WSWZD6ef5me31tukojh\n7SoS9ErhJXAPDw+PGsX1l8Cdy5MiMuoaSVK68+HHg7ZClr56Ua5xWclJYvgxLojQ3iqV3eZmSNpu\nblTJ0blCd4jJp0JepG1X305XUC9wzoVIRL7gmzpJMk7Vk0QxOyS5DBo5J0s1LOdo6SHpafOASKHn\nOA/I1l7ab8tmSYXZwG55sYlE0v0AACAASURBVIiML8Y1+EL1kv52LSIqr0uZa0VGVZRonF3/rErR\n291J1+3hv7fvkWrfvd18raoQUU2dNL+/eOnloO2551+gHzx/D+zdG2xLRUli6+wS6fniGecqeCxo\nmxojF1EXsdZYJ/tv20ruW32dIj0/8sh91LatP2ibZlfIeY7MO3HieLDNkZE6Mi8cF6l2LdbLhRJI\noSrlaIjvVZar0ydVzhfDBHhRRa0usBtrWBGQu24n7ccRkWOTsp5mON3w/IK4mS6xu6guzNHIkn+C\n10DHokiom7rJBTUWkbXQyJGECdXmxuok63JFE4v8W4nsbhbWi2x0KBZFeo7H6bmpVkRLKfM8F/U5\ngoK4Ll+LzF+VIyxX5sRV9Ynf+SIAIK9cFlvbSUN7/LHHAABTirwulGidjo+Ko4ErGnH//fcFbf/H\nn/5v/Ivm9PlfyZo/8/bbAICx4ZGgbfetdOwtO0WKLvI76pfPUrmEvKr1+vobJIEnVAGZ5HtEtW4E\nL4F7eHh41ChuAAmc/miXJhck09ImbmI2S1/i9gR9adMhCXg4w4UAMoviSlTI0tdssSJtTQ3s2sXF\nCpJJkYSKbMfMqZwiCc5/kUiLtNbKZcfOc2axOZWpMJuhc/RsFmmxfwtJQFUl+U6Mk03s5m0kXYZU\nYEyogb7asS7J5RFq4oCV96hW3d6oAlNYignFRIKssN0/ovJw3LKHco88+CgFFVRVlffZKs2bUVLB\nmdMk1R5647WgLc7lvHbuJUlyqSSuVS5TYUxJbsffpXOMXpD8L6U8XTfJJcH6VfXzvs009kc//kjQ\ntqWf3LKmVH6Kb3/3aQBAhscwPCqRTvXNJP0VyzqT4MaFCArsaqnloaLL0aEk6niK1kWIc6zMzcta\niHOGxeVlsecfPUX8QFOHaIrdffQ7zi6ueZW9cJYr2//s2f1B2xzbUZ2LHAC0savqnt27AACxpKyd\nlnZ6huqU3Thf4rErwTfO2fyiEVdIQblEht1vlcGRNVV7qf9hgLIay/ISB4GpHDTNdbTuk8p10gUl\npeLU76kpkZSXmAsY6NsqfbN0vjNnzwdtjz3+JADgh3/1IwDASlY4rCK7DD79ne8EbVkOgPqn/+yf\nBW0tzE+5pzYak2d0Wz/Zw7/39PeCtqYQzX3vdtG0m1tJG/3VLyin0/y8aAJTM+RyPDErpQI7Guj5\nzlxF6eDLSuDGmD5jzPPGmOPGmGPGmK9ye4sx5jljzBn+23y5c3l4eHh4fHi4EhNKGcC/tNbeAuA+\nAP/cGHMLgK8B2G+t3QFgP//fw8PDw+Ma4UpKqo0DGOffS8aYEwA2AfgcqFYmAHwbwAsA/vVV94CJ\nxbBSz5Jct7FUEbebApNTEY4obE0od6QBItyOnhB1q8xuX6WiqMr5IilEc1xnsaFBosKKHE2XV4ny\nl9gtq0GZJ4ZG6BoDA+TS19Yk+49eJHWou0edl4nSupSYg27aSYUcoi3U70Kj7J/nGorJTlGDSxG6\nfrKy8e3Kr+hE+dym5q/CpqRNLWKGyea4hierpjOTEr14+gQRNf07dgVtYXYpvPt2qQruiLvRMTJZ\nnFZVtjt53k6MiJo4PsypXVUum04mhut5/y7lQrllO0Vu9u4UF8oQk4AXT0lOjCP8O5Qggq5kdL4W\np+7LWiiXZG4uAZsRxieEUDxzhlT05hbpWxdXFncRnrqmYoXdUXU63hOnyGWwpUdMKCl2R41XuehE\nSswJs/McIasIOpfDo6xS3WZ57TrzX0Hl/piZo3PEYmIGnGN3zYoyF27tp/mNMZlaUcSiZZNSOiHr\nL+Hy7LwH8dbaLq6zzlWwvUn60cGFO0LKPXFlhQhKy4UfQkVJ8drtXPkikgPn8HEayzvHZO3+1Y9/\nRddqoP6GlBMCl6hFz1ZZ184F98KomDhODbo1y2lz4+KmWMe1dO/+6KNBW1sXtXV1yfpwNTy7euiZ\n7tgkzgp33kPPUFO3PPuTczSWJITovRyuisQ0xvQDuBPA6wA6+eUOABMAOjc45kljzEFjzMFs9iqM\nOx4eHh4e74krJjGNMXUAfgjgD621GU1yWGutMeuzGdbabwD4BgD09PSsk3GBpIfZIZGmTr9D+QQm\njkjAQ2mZCKtU1AUaqHMwodPRLmb44TH6tkRVybNIdHXmt6DyOoB8jjO5qTwSre305Ywpl7NIgvrb\nzMEk27ZtC7b1MiG1qMiKMBN4zU0q54ah81n+29IuxEd9Vx/vIhJ7BS4YY2OMjUnmRsO3taFZ8ph0\nMtF1/+3i5tTJ0t/yAkk5CxkJhLrr7nvpXCGRPEo5cpvavVVIpFdfoXt08ThJ3v0d4up48ewgACCn\nAqEynEciqrSOZJL6mWR3uLjSrm5l18awKu3msgq+8+4RaWNptWMTn1eEUJRYJdEFPN6rSHu+SAtk\nUAWGDU7QNZdlyeD0BZoPlwkymRKJc26eJMmSkobDHGxSKYlEaMoucyS77xVEM2hmUsuRkwBQtTQ3\n6QZxM0030nUjCTrXxTEhcI8cOUHHKSl3hgPU7rxL8nvMcjGIkUF6bjQ5mW6kddrXJjLars10nx2B\nuh46utRzw8UKzhyRXCFHF0niLKsyfyV287OsbSYbRKK99+GPAQCOn5Pna/8rtO4Xl2TML774nwAA\n/+RLHwUA5HNSeu9vnqXSjE2bRKOLca4Zq+5L0mksvE5cACEAgF0465PyfC1NEVF5+83yLJc4/8sw\n5zi596F7g23LJdr28lsScLbEAu7HdkgG0MvhiiRwY0wU9PL+jrX2R9w8aYzp5u3dAKY2Ot7Dw8PD\n48PHlXihGADfBHDCWvvv1aZnAHyZf38ZwF9/+N3z8PDw8NgIV2JCeQDAHwA4Yox5m9v+VwD/FsD3\njTFfAXARwO++nw5kJim15uvP/Thou3CY/Izz00J+xVht6eLou5xKOVookIoe1ZWpmeQpKjOJMUne\nj1TNuCIm6rkGXqmk/XxJHb84JBFXfX3k153JkIrs/KsBIJMllbu3XxFu/Le7pz9oy2apT5E49aMp\nJmpontOLxtrkvK5gwHvFael8GY2NpHbu2ilEaNLSHH3i3j1Bm6v7d/HcGQDA0aMSHXn3fQ8AAFrq\nRU2McdTsrDLXXDz6LgCgNE2q/+iUzkdD6vCSrrbNqXPDMSFqokxK3nwrpe7cc+fuYNumPlInT58X\nv/GXXqH18dLLr6oxk/msgU0z41NCQLpoQW320zVE1+Ick9GTC8LZ1LeSySBXkrFMzWdWnXdZqeAZ\nJsAHBweDNjfft7XJPajwenNpanVk4wqr1BdVNfNkgtaKrjcZSdI6ynGsQTYjJiuXyiauTFDOd3rw\nhKS1PXeEfkc49e+AWsMDm/q4b/JsLHHsRWvTxiaUu/aJ6efCGZrv5QVR1DNL/AxZ7ZPP4+fnNzsn\npouL5yiGoH2zmNim52geqlYcDQolGn8zE/YFlWq2wKebWZT3R4ULMzSoCNlurp8bjxMZfl4VGZnn\nNLINcTlvbpJMOA/uExNlnufryLv0XLXlxMQbr2MTUb3M30rx6uMqr8QL5WVs/O74+FVf0cPDw8Pj\nQ8F1j8Q89frzAICFoZNBW5rLOVVU8vxqiL6E1QRJWLGIfC0rC7x/UaSXEIseOj9FiSUUl+VN8Tow\nLJV0dQkJcZoJnaYWkUKTKeqH4T7mCiIhNLILYLpFCMt4jI5NK6IywoRIfYw0grOHTgTbDr1KxNzn\n/1TI0XR/P13zPepXpVQmPMPEqa4Y3s7RbqGsRAuGWQMAz3NrlxCQziUur/LFhLltbkKkqBgXCiiy\nxJQviTvoArspluPi0hfmMleJhBB+bRyZuJ3zSNxym7gpRjgC7uRpKVP38+coMnFBZS0McV6PGJfG\nS6v5cCW1tHSb01rBGgyOkDQ1u6jKzzky3Mr4Ukxku7wk+vwRjvKNxmWcjkiMKpe+opOaORK4qkjP\ncpXmu6m1Q9o4unFpWaS/xjaS7Nzq0AUM2pjY7+sU17t38yTxHntVMlqucKbE2A7S2upU9sct83St\nqSVFzneS5Nin3ObWYutWIePmec3Up+V5bKyn37OLktsky5n7OjjvTrkga3iBoxajzUKAZ/N0/URM\nlSDknDC/fP5vqaGoNBJ2Ly2qXC8VLnsXqRNpOMNRvrZC129qlHEul2lbNKKeOc62ePyIvMeq7Koa\nYkeAjMqF0sYus+l6IYYjkY21wo3gc6F4eHh41Cj8C9zDw8OjRnHdTSjzg0RMzA2K6lFgP+qQ8uFu\n7KIoJstmhFhSFUjIkUq6otTKFG9Pp8Wf+oEHSTUv5Uhliyv/7jquUn7shKjqJU5+lExLP1bYXzzB\niaI6OvuCbYYrymeUJtTSQNc/NyVqXJSTV1VZ7Tp9XsZ+7AT5U+94Xfxl7+t3yeQ3/t6uKFJ3maMy\n33lLVNPm20g1zqqq8VNTkwCA3l1EGt77kY9IH8M0lnMnxD//ncPEYSch81Gu0O8Sm0S6+vqDbaNc\nZR71omrGmBTtaBNzTQPXtty6g5J75VRK3+kJ8qE9cOBg0LawyHOpUqpmOSHW9CyNL6EiGiNh52v9\nHiXUFVyyp5Exiex1xQcWFAmX4oIYWzYT4VdU/swVTqoVT8rYAzOX6neOo4NdVGxYmcniaZqrHbuE\n1HV1JgvKdBfndVdXR/egfbuo+yEmBRtVP4ps5lpSa2aJXwXLS2QeaJgWv+qtHA8RT8jzEuPYi+WV\njYPzHtgpFNnBn1HyqKU5IZfruN5qpaCSZPGtb0yTOSMXlm0lJjsLKomZ5URV2lwY4xTIrZzAq1JS\nr7kyX39VBCltX1JxEKcP03qbn6Vrbd97t1zTpeFV5Gu1zDVhVYGXMBf/iKY4dkURyZMc9TkxImap\nEKf0faBX7vfl4CVwDw8PjxrFdZfAF4ZI4o0WRELN5ki6iCTkKxmtUluVo5uW81Ipfolzm4xclC9o\nYwORA4cPSW6OeJS+5tv7SaI4NynuWa5k1tSM5F7o2UluUPmiuhZHhJZZAm/Kyxe3woRUS48QQEfP\nkxS376FPBG1dA0RQlpkgefze3wq2bX+cSMz5ZUni7/JeRKxKwL8GOtLOJd6vKkKxtZEkmiYVATl+\nYZDHRHO/mBGCs7WFpK13jx0N2n71GmkFH/vII0GbZVJ55+23AAAmM9LvDEs5jSodb/smui9FVbF8\nz15Ka+vcCUcVSfrd730fAHD4LXHjchldI8pt1EVZ5njt6Fwebr+4IlNXuZyuQYJTnrardMZJPra3\nVwjFiUnSYE6epPJzuqydk6R1STB3/fo6IcVdWtgwp2zVBKTLH7KqjQnQtEpvGuFjEyyJV7U74wqt\n3fk5kVpnmChcVDlClrnrS/xcZVWumC27aL1GVXm9Kdack5GN44NbElJdfXaCNKO00saqfL5SSZPF\ndF/KFerbyoqsScMFNBanRItcmKO1m1+RdZdgV9VXD/DzrVJPz8wxYVmWZ9rdq0pF5ZdZ5O08D0tT\n8q6w7HywWJF3hbManMzLfIS5oEou7wrIyFiqlvqh9QDjCzp4eHh4/P2Bf4F7eHh41CiuuwklmyHV\nIxYW9aG5kQhLExWiJsP1BDOseq8oIiPLJSwmZ0TFMwkytYxnRH2a498TnOynUfmTJjgxTapJIrrS\nrdQ2PCzqWZWjEQvsy72oKq6cG6cIxUdvvidoG+ggQmn3A0LoGPYNrrACpYqfY/cn2F+8Kmpl2SWU\nsht/b0MqMs9FtrU1yfh2bqfq17Gk+OG2tBOR2L25HwBQ3yh+sBeGBgEAaZVKd9tuiiA8OTwZtN18\n7yMAgEOczvXNd4Rs7OBqMD0d4hff3ULX6GwXU4RLuvXCi1R3cP8LLwXbjh8ngtelAgaAJPsSW+ia\njrS9yOShVkedmUL7aa8yOa1BkSNqY6pKeYyr7lTVOXo5ZmAT+1jnVcKjYpnrryri1B2pq6Q7v/kK\nm+IqKooyx8RmVNWudOq+Ju3CLt0rRxY31AvBH+Wq9PWtYtZbDnP0Z5fc2/4Wuh9NDfTsbVV+4+dO\nUZyCS4IFAHtv7gcAtLVJitS1qBiZ463sX55ulWuOTXBVmolJrIUzR6WVH32YyfNcRcxvn3iCnqtQ\nXNb14UO0FqeW+X4YFU8So1deaUmeW0fEF5SJsr6Ono36FK3NvIrcLBk6b7SqUlobOu/ssow57CJX\nwzQGa6Tf1nIq57g6x3s83xvBS+AeHh4eNYrrLoHbCH2lMoqsmJ7munxplReCBemVLEmmReUyODZH\nX7OhJfn6ReMkLcxnRYp69xxJ0pFlklgmxoUs6+gjV7D6FpEM81kiKUqqDmIoRARJNU/Xzyky9dQZ\nkiTur4iU8bFP/jb1V+VkiZXZrYi1jrCRr7CtkjRgwiJ5RFhSf6/6g3HlVhni1KT1deJKV3DRpyGR\nhus4usyl0J2cEkkos0z349zQxaDtIpOLvZsk38Mbx4gkPsgRaH2bJYJ0N9cHbJKu4a47iewsqnqd\nbxyklJo/f44k75lZkXaKHHloFEEYZffPsiKdIhEm9Zgc0hJ2nolN3RZRboZrsWUzkW+zR8SlNMOF\nPi5cFDJrgYmu3ZzDJanuQZyjASvrJAFOqBqQUSa63FoIrSoKwWS0SnFccbUoy6JZuhS0DZwPp6Nd\nNK9W1oISjSKhzi2ThtHSIvvFeQ1WWEs9d0iiNJ+7QLlyllXRkJ1PUQGu+kYhZNdic4+stT/6F1Sn\n8j9/878FbSU3BjVFJdZIRsdIOu9sFiK5hyN2h1WeG6ecxNNC6pYs/a6AtA5r5R1QKvIzrwq9GK5H\nWlVFQCp8TKXIz56iG0N8z4rKnRbBPVI5apiILRazfJysv3Qd7b+yINq907iuBl4C9/Dw8KhRXHcJ\nvAKyT62oaj0JlrDaVJ6FZbZ9h8PkhtRWtznYdmaCJIPcCbHRjU1yKamwfN6zGXYJ4sIO9c3i3nbq\nrUEAQDUkGRBvv58kSGPFHu2q11e5P+kZ0RxubibJ+2//838J2nYPUI6Gc+dFmtt1z0M0hgGSZKtK\nAnduZ+9VvGE9NCr3rD17yP1xa6tIL3kWIPa//HLQZthd7vM3kX08nRIJ5M03yG3v+InBoG1gK0nP\np89Km3Oh62aptaFBxrJ1gIKc+rukH9u54vzbg1JF/OVXSQKfnCKNx1otCdFf7TJYZttiRTthOVGE\nhZzVVdVpY0XlGVleESl/LSzbrbu7xA4cYftyukEkziHOEphKcqEGZZsts6Q8Oy9czZEj5CLa3S3n\n3b6DNJZ8gfpTyItk3dToKsqLpBxjTSMSv9SuW8jRM6TXzgJff/SYZJo8f4HmflhlOZwcJXfX+Rku\nRKGyNYZ5/hrSomGUivRMrKdhOGRGJNvh+SPkdvj2yy8GbYMz9IxW1TncfXPZIpuaxXZfxwUuymOS\nHXQLu6UeeFOKe+QypBmFYswxqfte4UAbq4gnw9FDVQiHYV2WUSdkV0XadgU5qqpEn+NX7KpcNsxv\ncNGalCpU8od/9D/TmFTOnvFxCRy7UngJ3MPDw6NG4V/gHh4eHjWKy5pQjDEJAC8CiPP+P7DWft0Y\nMwDgaQCtAA4B+ANr7VXnQ0y19QMAYhOibuU4JejSvMr3wLkcWutJhWyMSNTl43uILHn0LqnVmC3R\ntym3JPuNnqe8GukEnUulpMD0JKnvI6oydS5D541ERVUqVEnVdZpSXrl93bmDIgovXBRV6OIvfggA\naOkQcnTobXK1a9x8MwDARuU7aoK/V2dE+eiD9we/9+ymnCKhqpgRZkdJ7WzbJKanV1+lepY/+D4V\nU9p3t+R7GBshVXrXLnGJfOlFKqQwNS0q7LYdpMK2dJJ63dEh5pJ0E92rTdvkvozPk8np734mppzT\nZ+h8IY600wFpzvxho4roZROHVW5+HHyKEN+qsnLVc+RlTEUvuqjZ9XD6NLmhHX7rVNC2azeZj7pV\nRfktW2guo9FLI2QLbAKYXxSSKhJ2KXp1HhM6dilDbQdelRw4JSZw77zjrqCtqamF+y+mlhATbnkX\ndTkjZsBDh94EsLqwRIFT6VbL68wfk8U6b4xzzWzqEdPPANeCrb5HmZGSqg0by9FzeNtWyR104gwR\n4EYVinAmFGfCyav8Mg2tjpSU/R+6j9bnOZVu+FieSNdShchOXec2xHNaLascLnw+HblcqbA5ivsT\njYq51aWqtuoZdfOQSouJra6O1luK3XlTjYpordL5Bzj/DwDs3E3PyWu/FAL5crgSCbwA4FFr7e0A\n7gDwhDHmPgD/DsB/sNZuBzAP4CtXfFUPDw8Pjw+MK6nIYwE4MTPK/yyARwH8I27/NoA/BfBnV9uB\nOx7/BwCA2Wn5gqabObNXUWUpc0Ev/M05d0FynPSzi144JV/Vbq46PXDbrUFb4Y5+AECeJbKyyug2\neI40gHSdSG6znMi+d5sqe7RCpFA4QoTKiiLLzkxSnzp6FHmYJ+kyPCYui8t8XuOkqFUSnJMuri4v\nQosKSnKZ6ioqM9o771Iwxp7tIg1/5KFPAwAGL9DYz5yTPs4v0DkOvvXzoK3Ilcu3bxdXQQsOmOLM\nfbt3y3zfehsF/hjlGlesBCxj0Oay3JWKXPBAS9tuPpREGGMCT7sFFjlIIhRmFzIlXbr5yOUUUa4K\nSqyFk1bPnxeidYXdCJsviItoA1eGb2IJq16Vn6vj380NyqX04YdpfCowp8KuZrk83ZcdW0UiGxsl\nt85kQoiuMo+5oMZSKVLfkhyIlVH5aM6dozWp89xE+PpR5Zqp7xGwem6da98994qWF2Vt5sSp09gI\nUSUfdrdTwM8XHns4aOtoobl544jk25ngMnUzrNkmEvKKinAOkpUVcbf7i29+g/afE2k/AnpGSy6Q\nRz1LgUtwSEnlPA8d7UKYdraRtuGI8ovDw8G2DGtV6+nITV3irtm3lbTucpjWYn2juI++8ioVJTnw\nxq+CNudUcM/Oj61z5vVxpVXpw1wPcwrAcwDOAViwNsinOAJg0wbHPmmMOWiMOZjNbpx60sPDw8Pj\n6nBFL3BrbcVaeweAXgD3ANh1mUP0sd+w1u6z1u5LvUfwhIeHh4fH1eGq/MCttQvGmOcB3A+gyRgT\nYSm8F8Doex+9Pm5+6AkAEokGAG/9itSKuSmJApyfJfU+VU9qTqJH1cpjtTxRlrZj50j9Xc5KpGSU\nGa5shUic9hYhpJKsBkcbxG+3KUW+zR2bxISS5Ci6+Sm65qnzg8G2CKu1ugDE3HHqR2dM1OamATIZ\nhLg4hFFpTkOG1FULabsSON9eAJiZIhNDWfsUc53OSFJyVwyx36mJk7/964dFHX77XSJatVmgtYdU\nwpTyBw6zOt4Up6WUSsr+VU6DOzImxQFchfVsXtTgFNdGdD7QFVWk3Kn2VUVcOfW+oOpalp1vbvXS\n+peOGFtlciluXBNTriXryRW/mF+U9ZHiyMfWVpo/TZw6E05CpYJ1Jhe3PwA0ujS/XHd1S6+QfAN9\nZFZZWJA1PMMFERYhJqIpRxbyxC2oGpNuHmKqvqwjKJsaZF2XOb4hx/dFj6VnEynXXT1S13X/8y9Q\nP9S1EFkdlVnVSX54LcSU6eyum8kUt7lPEfzsTHB+lNbM6KyMfXiYzJEFFUX5058/BwBIpuT5SsTJ\n5BRnk4S6JMIp9udX67qZn/3tW8U0uK1/gM9Lz/uBN14Ptu3fT+YPq9ZTmJn3SkHWdXaO/dy5jmpu\nUiJIXX3biMqFknSxHBLofFlcVgI3xrQbY5r4dxLAYwBOAHgewBd4ty8D+Osrv6yHh4eHxwfFlUjg\n3QC+bYwJg17437fW/sQYcxzA08aYfwPgLQDffD8dKIeJyNj14D8M2rbvIal8dmYwaFvmhO2mTMTE\nqQMS0bV0gUiQRFW+fvl5+pLPKXJj5CK5V71zmiTldKPkariJK6Hf8Zg403TfTITcyz/7VtAWCdOX\nu2SJbClm5fPe2ERf68qKfJk7Gkh6aVQSQoWJubMs5e584JFgm3WRo1eZ2z2vSK0yF6DoVHld7thD\n7lad7SLhje0n6enHP6Zv75Iiujb3UTY2HcnqKpzv2SNE5RxLf0nOu/L6gTeDbW8dohJsWlKZn6f7\nODQphGlPD/XJ8HI8d05cSp0EqUk2J0lrVzfndrZeBXoHHZ2po/PWIplw5fhUZXumrFay4pY6N0sS\nVZA5T+2/wnlDhgdF6nIaQ0KVJmtsWC2BNzUKkVbP2ubysqzreV7XOaVZFrk0muVI0GlVtizHLot6\nOTVwhslHPyZkWROXH3PRpSXlUjfABUgKqtRddpbmwUWhAkBp7ZSr+U6x5qpdKPMFWrOtKZmPcCdp\nJ1HWMIqq3NpbByjasqCjRDkytaT6VshT39ZbAy6i1xX+AIBljtycU8Vczp4hV8Re1oj02nEFNvRY\nGlii/4ef/3zQtm0zuZmWmfubnBBNdIYr1A+paNj5CSGfrxRX4oXyLoA712k/D7KHe3h4eHhcB/hI\nTA8PD48axXVPZgVOyl+20pUwRzB1KpKlM1BhSFXq7hc1fn6UyM6k8h8eukB+5RdPvRW0JcJE0u1p\nJBLk+dcl0q6vkaIi7/+9rwZtFZDqmnhTogbHTlA04rkLdM2iSmla4ATvY3OqkjZP8WJIPHAWc2Sq\nWDryLgBgx/3iG2tDtH/4Kk0ojU2KaI3TwbfulurW6XpSU//rtyXR1giTQk1dpPrHGuV73tJOKvXu\nHduDti1byLde12h0hTbefYfMWOcUmbrMtTZ1rUiXFjYUF7XZcPXuzg4y2wyNSCRrlSPxylVRkZ06\nuyphlatBGb5UbQ4FNQ/Lqm1j2aWujkjV+nrx6c1z3cZyRfrt0n8ucErQojI71LEZpqNdSONJNhvN\nzsyoNlKrYxyNG1cFDNKpBh6TihMIcVRpRBV0YPNOlJsaFEF39137AAAtKrFZcwv93j4gMQGNXKdz\nx44dPE493zR/p89IrEaYo5O18wGiq4l3nRBrhdMZa0KxmU050RVpdLEf7UyUb+sWwreX1+SMqu8Z\npNpVhKkmvNfCmYa0izcdagAABZJJREFUiSjv7qNKPDY2TubWUxyVq5OpFYvrBJzzwKZU0YsmJkDb\n+T22e6f4+IfYbJRdkWd0hYvDiHHs8vASuIeHh0eNwqxn6P91oaenxz755JPX7HoeHh4evwl46qmn\nDllr961t9xK4h4eHR43Cv8A9PDw8ahT+Be7h4eFRo/AvcA8PD48axTUlMY0x0wBWAMxcbt8bHG2o\n7THUev+B2h9DrfcfqP0x1FL/t1hr29c2XtMXOAAYYw6ux6bWEmp9DLXef6D2x1Dr/Qdqfwy13n/A\nm1A8PDw8ahb+Be7h4eFRo7geL/BvXIdrftio9THUev+B2h9DrfcfqP0x1Hr/r70N3MPDw8Pjw4E3\noXh4eHjUKK7pC9wY84Qx5pQx5qwx5mvX8trvB8aYPmPM88aY48aYY8aYr3J7izHmOWPMGf7bfLlz\nXU9wUeq3jDE/4f8PGGNe5/vwl8aY2OXOcT1hjGkyxvzAGHPSGHPCGHN/Dd6DP+I1dNQY8z1jTOJG\nvg/GmL8wxkwZY46qtnXn3BD+E4/jXWPM3uvXc8EGY/g/eR29a4z5767aGG/7Yx7DKWPMb12fXl8d\nrtkLnCv6/BcAnwRwC4DfN8bccq2u/z5RBvAvrbW3ALgPwD/nPn8NwH5r7Q4A+/n/NzK+CiqD5/Dv\nAPwHa+12APMAvrLuUTcO/m8AP7PW7gJwO2gsNXMPjDGbAPwvAPZZa28FEAbwRdzY9+FbAJ5Y07bR\nnH8SwA7+9ySAP7tGfbwcvoVLx/AcgFuttXsAnAbwxwDAz/UXAezmY/4f4/Lo3sC4lhL4PQDOWmvP\nW2uLAJ4G8LlreP2rhrV23Fp7mH8vgV4cm0D9/jbv9m0An1//DNcfxpheAJ8G8Of8fwPgUQA/4F1u\n9P43AvgouGSftbZorV1ADd0DRgRA0hgTAZACMI4b+D5Ya18EMLemeaM5/xyA/9cSDoAKnndfm55u\njPXGYK19lguxA8ABUEF2gMbwtLW2YK29AOAsaqDi2LV8gW8CMKz+P8JtNQFjTD+otNzrADqtta7q\nwASAzg0OuxHwHwH8KwAuy30rgAW1iG/0+zAAYBrAf2Mz0J8bY9KooXtgrR0F8H8BGAK9uBcBHEJt\n3Qdg4zmv1Wf7nwD4Kf+uyTF4EvMKYIypA/BDAH9orc3obZbceG5IVx5jzGcATFlrD13vvnwARADs\nBfBn1to7QakYVplLbuR7AABsK/4c6GPUAyCNS1X7msKNPueXgzHmT0Am0u9c7758EFzLF/gogD71\n/15uu6FhjImCXt7fsdb+iJsnnYrIf6c2Ov464wEAnzXGDIJMVo+C7MlNrMoDN/59GAEwYq19nf//\nA9ALvVbuAQB8AsAFa+20tbYE4Eege1NL9wHYeM5r6tk2xvxjAJ8B8CUrftQ1NQaHa/kCfxPADmbe\nYyDC4JlreP2rBtuLvwnghLX236tNzwD4Mv/+MoC/vtZ9uxJYa//YWttrre0HzfcvrbVfAvA8gC/w\nbjds/wHAWjsBYNgYs5ObPg7gOGrkHjCGANxnjEnxmnJjqJn7wNhozp8B8D+yN8p9ABaVqeWGgjHm\nCZBJ8bPW2qza9AyALxpj4saYARAh+8b16ONVwVp7zf4B+BSI+T0H4E+u5bXfZ38fBKmJ7wJ4m/99\nCmRH3g/gDIBfAGi53n29grE8AuAn/HsraHGeBfBXAOLXu3+X6fsdAA7yffgxgOZauwcAngJwEsBR\nAP8fgPiNfB8AfA9kry+BtKCvbDTnAAzIw+wcgCMgb5sbdQxnQbZu9zz/V7X/n/AYTgH45PXu/5X8\n85GYHh4eHjUKT2J6eHh41Cj8C9zDw8OjRuFf4B4eHh41Cv8C9/Dw8KhR+Be4h4eHR43Cv8A9PDw8\nahT+Be7h4eFRo/AvcA8PD48axf8Pl0FnmTRuYIEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "frog ship ship truck\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASNNvxWqGEgL",
        "colab_type": "text"
      },
      "source": [
        "#### The CNN Model\n",
        "Below an example of a simple \"Light\" AlexNet network - that is, 2 CONV layers followed by 3 FC layers. ReLU and max pooling is used as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LeQqFNJGVwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6kKZQiiHsJF",
        "colab_type": "text"
      },
      "source": [
        "#### Training\n",
        "To train a neural network, we need to choose an optimizer and define a loss function.\n",
        "As an optimizer, we choose the stochastic gradient descent (SGD) with a learning rate (LR) of 0.01.\n",
        "The loss function we choose is cross-entropy loss which is defined as\n",
        "\n",
        "$$\n",
        "\\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)\n",
        "                       = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right),\n",
        "$$\n",
        "\n",
        "which is a composition of a log-softmax function and a negative log-likelihood loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvayn2lyH6Ay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "LR = 0.01\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.SGD(net.parameters(), lr=LR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSUOSxPHOFbZ",
        "colab_type": "text"
      },
      "source": [
        "We define a training function and a validation function.\n",
        "\n",
        "For each batch, the training function feedforwards the inputs from the training set through the network (*model(images)*), computes the loss versus the reference or ground truth (*criterion(output, target)*), backward propogates the gradients from the loss function (*loss.backward()*), and updates the parameters (*optimizer.step()*).\n",
        "\n",
        "The validation function uses the validation set, which the network did not explicitly trained on, to check the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ico_4YPFkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time, losses, top1, top5],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        images = images.cuda(non_blocking=True)\n",
        "        target = target.cuda(non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        output = model(images)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1[0], images.size(0))\n",
        "        top5.update(acc5[0], images.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            progress.display(i)\n",
        "            \n",
        "            \n",
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(val_loader),\n",
        "        [batch_time, losses, top1, top5],\n",
        "        prefix='Test: ')\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            images = images.cuda(non_blocking=True)\n",
        "            target = target.cuda(non_blocking=True)\n",
        "\n",
        "            # compute output\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), images.size(0))\n",
        "            top1.update(acc1[0], images.size(0))\n",
        "            top5.update(acc5[0], images.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                progress.display(i)\n",
        "\n",
        "        # TODO: this should also be done with the ProgressMeter\n",
        "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
        "              .format(top1=top1, top5=top5))\n",
        "\n",
        "    return top1.avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGjpLMJ7RCCF",
        "colab_type": "text"
      },
      "source": [
        "Below are additional auxiliary functions (e.g., gathering statistics)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywJBdnxWPVwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "      \n",
        "      \n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "      \n",
        "      \n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5UE8tbmcK3b",
        "colab_type": "text"
      },
      "source": [
        "It's training time! we'll try 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7-bY1z_PYj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e96d553c-e381-4161-8cf9-2a17003c36ad"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(0, EPOCHS):\n",
        "    #adjust_learning_rate(optimizer, epoch, args)\n",
        "\n",
        "    # train for one epoch\n",
        "    train(trainloader, net, criterion, optimizer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    acc1 = validate(testloader, net, criterion)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0][  0/391]\tTime  0.144 ( 0.144)\tData  0.128 ( 0.128)\tLoss 2.2974e+00 (2.2974e+00)\tAcc@1  10.16 ( 10.16)\tAcc@5  52.34 ( 52.34)\n",
            "Epoch: [0][100/391]\tTime  0.044 ( 0.031)\tData  0.038 ( 0.023)\tLoss 2.3037e+00 (2.3046e+00)\tAcc@1  12.50 (  9.78)\tAcc@5  47.66 ( 49.27)\n",
            "Epoch: [0][200/391]\tTime  0.043 ( 0.029)\tData  0.038 ( 0.021)\tLoss 2.3087e+00 (2.3045e+00)\tAcc@1   7.81 (  9.51)\tAcc@5  43.75 ( 49.39)\n",
            "Epoch: [0][300/391]\tTime  0.056 ( 0.029)\tData  0.052 ( 0.021)\tLoss 2.2989e+00 (2.3039e+00)\tAcc@1   9.38 (  9.53)\tAcc@5  51.56 ( 49.63)\n",
            "Test: [ 0/79]\tTime  0.122 ( 0.122)\tLoss 2.3005e+00 (2.3005e+00)\tAcc@1  12.50 ( 12.50)\tAcc@5  53.12 ( 53.12)\n",
            " * Acc@1 9.810 Acc@5 52.460\n",
            "Epoch: [1][  0/391]\tTime  0.153 ( 0.153)\tData  0.141 ( 0.141)\tLoss 2.2988e+00 (2.2988e+00)\tAcc@1   9.38 (  9.38)\tAcc@5  54.69 ( 54.69)\n",
            "Epoch: [1][100/391]\tTime  0.032 ( 0.029)\tData  0.026 ( 0.022)\tLoss 2.3017e+00 (2.3009e+00)\tAcc@1   5.47 (  9.46)\tAcc@5  54.69 ( 53.10)\n",
            "Epoch: [1][200/391]\tTime  0.054 ( 0.028)\tData  0.048 ( 0.021)\tLoss 2.2972e+00 (2.3002e+00)\tAcc@1  10.16 (  9.69)\tAcc@5  57.03 ( 54.64)\n",
            "Epoch: [1][300/391]\tTime  0.046 ( 0.029)\tData  0.041 ( 0.022)\tLoss 2.2928e+00 (2.2995e+00)\tAcc@1  19.53 ( 10.18)\tAcc@5  63.28 ( 55.41)\n",
            "Test: [ 0/79]\tTime  0.129 ( 0.129)\tLoss 2.2930e+00 (2.2930e+00)\tAcc@1  21.09 ( 21.09)\tAcc@5  63.28 ( 63.28)\n",
            " * Acc@1 16.880 Acc@5 60.780\n",
            "Epoch: [2][  0/391]\tTime  0.156 ( 0.156)\tData  0.148 ( 0.148)\tLoss 2.2906e+00 (2.2906e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  63.28 ( 63.28)\n",
            "Epoch: [2][100/391]\tTime  0.012 ( 0.030)\tData  0.000 ( 0.023)\tLoss 2.2914e+00 (2.2934e+00)\tAcc@1  14.06 ( 17.06)\tAcc@5  65.62 ( 62.01)\n",
            "Epoch: [2][200/391]\tTime  0.007 ( 0.029)\tData  0.001 ( 0.022)\tLoss 2.2895e+00 (2.2909e+00)\tAcc@1  19.53 ( 18.08)\tAcc@5  60.94 ( 64.56)\n",
            "Epoch: [2][300/391]\tTime  0.047 ( 0.028)\tData  0.042 ( 0.021)\tLoss 2.2722e+00 (2.2873e+00)\tAcc@1  22.66 ( 18.66)\tAcc@5  69.53 ( 65.77)\n",
            "Test: [ 0/79]\tTime  0.139 ( 0.139)\tLoss 2.2440e+00 (2.2440e+00)\tAcc@1  25.78 ( 25.78)\tAcc@5  74.22 ( 74.22)\n",
            " * Acc@1 21.970 Acc@5 67.920\n",
            "Epoch: [3][  0/391]\tTime  0.133 ( 0.133)\tData  0.123 ( 0.123)\tLoss 2.2474e+00 (2.2474e+00)\tAcc@1  24.22 ( 24.22)\tAcc@5  71.09 ( 71.09)\n",
            "Epoch: [3][100/391]\tTime  0.050 ( 0.030)\tData  0.044 ( 0.023)\tLoss 2.2293e+00 (2.2323e+00)\tAcc@1  18.75 ( 21.82)\tAcc@5  66.41 ( 68.78)\n",
            "Epoch: [3][200/391]\tTime  0.007 ( 0.029)\tData  0.000 ( 0.022)\tLoss 2.1576e+00 (2.1963e+00)\tAcc@1  20.31 ( 22.71)\tAcc@5  70.31 ( 70.23)\n",
            "Epoch: [3][300/391]\tTime  0.011 ( 0.029)\tData  0.000 ( 0.022)\tLoss 2.1350e+00 (2.1561e+00)\tAcc@1  21.88 ( 23.69)\tAcc@5  68.75 ( 71.87)\n",
            "Test: [ 0/79]\tTime  0.128 ( 0.128)\tLoss 1.9288e+00 (1.9288e+00)\tAcc@1  35.16 ( 35.16)\tAcc@5  84.38 ( 84.38)\n",
            " * Acc@1 28.720 Acc@5 79.120\n",
            "Epoch: [4][  0/391]\tTime  0.138 ( 0.138)\tData  0.130 ( 0.130)\tLoss 2.0585e+00 (2.0585e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  73.44 ( 73.44)\n",
            "Epoch: [4][100/391]\tTime  0.058 ( 0.029)\tData  0.052 ( 0.021)\tLoss 2.0556e+00 (1.9847e+00)\tAcc@1  24.22 ( 28.57)\tAcc@5  78.12 ( 78.85)\n",
            "Epoch: [4][200/391]\tTime  0.034 ( 0.029)\tData  0.029 ( 0.021)\tLoss 2.0130e+00 (1.9662e+00)\tAcc@1  30.47 ( 29.25)\tAcc@5  75.78 ( 79.68)\n",
            "Epoch: [4][300/391]\tTime  0.015 ( 0.028)\tData  0.010 ( 0.021)\tLoss 1.9349e+00 (1.9544e+00)\tAcc@1  28.91 ( 29.83)\tAcc@5  81.25 ( 80.07)\n",
            "Test: [ 0/79]\tTime  0.141 ( 0.141)\tLoss 1.8403e+00 (1.8403e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  83.59 ( 83.59)\n",
            " * Acc@1 32.380 Acc@5 82.470\n",
            "Epoch: [5][  0/391]\tTime  0.145 ( 0.145)\tData  0.134 ( 0.134)\tLoss 1.9655e+00 (1.9655e+00)\tAcc@1  32.03 ( 32.03)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [5][100/391]\tTime  0.014 ( 0.029)\tData  0.000 ( 0.022)\tLoss 1.8823e+00 (1.8985e+00)\tAcc@1  33.59 ( 31.95)\tAcc@5  83.59 ( 82.33)\n",
            "Epoch: [5][200/391]\tTime  0.041 ( 0.029)\tData  0.035 ( 0.022)\tLoss 1.9705e+00 (1.8845e+00)\tAcc@1  21.09 ( 32.21)\tAcc@5  82.03 ( 82.79)\n",
            "Epoch: [5][300/391]\tTime  0.057 ( 0.029)\tData  0.050 ( 0.022)\tLoss 1.8967e+00 (1.8719e+00)\tAcc@1  32.03 ( 32.91)\tAcc@5  82.03 ( 83.21)\n",
            "Test: [ 0/79]\tTime  0.144 ( 0.144)\tLoss 1.7664e+00 (1.7664e+00)\tAcc@1  30.47 ( 30.47)\tAcc@5  85.16 ( 85.16)\n",
            " * Acc@1 35.350 Acc@5 85.450\n",
            "Epoch: [6][  0/391]\tTime  0.150 ( 0.150)\tData  0.137 ( 0.137)\tLoss 1.7790e+00 (1.7790e+00)\tAcc@1  35.16 ( 35.16)\tAcc@5  86.72 ( 86.72)\n",
            "Epoch: [6][100/391]\tTime  0.043 ( 0.029)\tData  0.038 ( 0.022)\tLoss 1.9347e+00 (1.8046e+00)\tAcc@1  31.25 ( 35.23)\tAcc@5  85.16 ( 85.22)\n",
            "Epoch: [6][200/391]\tTime  0.007 ( 0.029)\tData  0.000 ( 0.021)\tLoss 1.8246e+00 (1.7917e+00)\tAcc@1  32.81 ( 35.35)\tAcc@5  86.72 ( 86.03)\n",
            "Epoch: [6][300/391]\tTime  0.041 ( 0.028)\tData  0.035 ( 0.021)\tLoss 1.8004e+00 (1.7807e+00)\tAcc@1  31.25 ( 35.63)\tAcc@5  88.28 ( 86.27)\n",
            "Test: [ 0/79]\tTime  0.131 ( 0.131)\tLoss 1.6603e+00 (1.6603e+00)\tAcc@1  41.41 ( 41.41)\tAcc@5  87.50 ( 87.50)\n",
            " * Acc@1 37.370 Acc@5 88.430\n",
            "Epoch: [7][  0/391]\tTime  0.134 ( 0.134)\tData  0.115 ( 0.115)\tLoss 1.5793e+00 (1.5793e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [7][100/391]\tTime  0.013 ( 0.028)\tData  0.000 ( 0.021)\tLoss 1.6417e+00 (1.7206e+00)\tAcc@1  39.84 ( 38.07)\tAcc@5  89.06 ( 87.96)\n",
            "Epoch: [7][200/391]\tTime  0.043 ( 0.029)\tData  0.038 ( 0.021)\tLoss 1.6392e+00 (1.7104e+00)\tAcc@1  43.75 ( 38.29)\tAcc@5  89.84 ( 87.93)\n",
            "Epoch: [7][300/391]\tTime  0.013 ( 0.029)\tData  0.000 ( 0.021)\tLoss 1.6135e+00 (1.6972e+00)\tAcc@1  44.53 ( 38.50)\tAcc@5  87.50 ( 88.15)\n",
            "Test: [ 0/79]\tTime  0.153 ( 0.153)\tLoss 1.5989e+00 (1.5989e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  88.28 ( 88.28)\n",
            " * Acc@1 39.790 Acc@5 89.410\n",
            "Epoch: [8][  0/391]\tTime  0.149 ( 0.149)\tData  0.134 ( 0.134)\tLoss 1.6595e+00 (1.6595e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [8][100/391]\tTime  0.044 ( 0.030)\tData  0.039 ( 0.023)\tLoss 1.6679e+00 (1.6335e+00)\tAcc@1  38.28 ( 40.20)\tAcc@5  89.84 ( 89.93)\n",
            "Epoch: [8][200/391]\tTime  0.052 ( 0.030)\tData  0.046 ( 0.022)\tLoss 1.6120e+00 (1.6404e+00)\tAcc@1  43.75 ( 40.38)\tAcc@5  91.41 ( 89.48)\n",
            "Epoch: [8][300/391]\tTime  0.040 ( 0.029)\tData  0.035 ( 0.022)\tLoss 1.6772e+00 (1.6355e+00)\tAcc@1  39.06 ( 40.57)\tAcc@5  90.62 ( 89.57)\n",
            "Test: [ 0/79]\tTime  0.120 ( 0.120)\tLoss 1.5486e+00 (1.5486e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  89.06 ( 89.06)\n",
            " * Acc@1 41.850 Acc@5 90.550\n",
            "Epoch: [9][  0/391]\tTime  0.148 ( 0.148)\tData  0.133 ( 0.133)\tLoss 1.5258e+00 (1.5258e+00)\tAcc@1  38.28 ( 38.28)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [9][100/391]\tTime  0.030 ( 0.029)\tData  0.025 ( 0.021)\tLoss 1.4925e+00 (1.5820e+00)\tAcc@1  46.09 ( 42.71)\tAcc@5  92.19 ( 90.56)\n",
            "Epoch: [9][200/391]\tTime  0.043 ( 0.028)\tData  0.037 ( 0.021)\tLoss 1.4704e+00 (1.5740e+00)\tAcc@1  50.00 ( 42.58)\tAcc@5  89.84 ( 90.76)\n",
            "Epoch: [9][300/391]\tTime  0.037 ( 0.028)\tData  0.032 ( 0.021)\tLoss 1.5384e+00 (1.5735e+00)\tAcc@1  47.66 ( 42.77)\tAcc@5  90.62 ( 90.72)\n",
            "Test: [ 0/79]\tTime  0.115 ( 0.115)\tLoss 1.5178e+00 (1.5178e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  90.62 ( 90.62)\n",
            " * Acc@1 42.740 Acc@5 90.590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gDAr-ChiCIv",
        "colab_type": "text"
      },
      "source": [
        "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/0/04/Barack_Obama_Mic_Drop_2016.jpg\" alt=\"Mic drop\" width=\"600\"/></center>"
      ]
    }
  ]
}